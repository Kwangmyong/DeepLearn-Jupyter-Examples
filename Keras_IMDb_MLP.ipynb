{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "filePath = \"data/aclImdb_v1.tar.gz\"\n",
    "\n",
    "# note: need to create the directory \"data\" by yourself\n",
    "if not os.path.isfile(filePath):\n",
    "    result = urllib.request.urlretrieve(url, filePath)\n",
    "    print('downloaded: ', result)\n",
    "\n",
    "# unzip the tar file\n",
    "if not os.path.exists(\"data/aclImdb\"):\n",
    "    tempTarFile = tarfile.open(\"data/aclImdb_v1.tar.gz\", 'r:gz')\n",
    "    result = tempTarFile.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regular expression (to remove the HTML tag)\n",
    "import re\n",
    "\n",
    "def remove_tags(text):\n",
    "    regular_expression_tag = re.compile(r'<[^>]+>')\n",
    "    return regular_expression_tag.sub('',text) # replace as ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# read files (positive or negative)\n",
    "def read_files(file_type):\n",
    "    path = \"data/aclImdb/\"\n",
    "    file_list=[]\n",
    "    \n",
    "    positive_path = path + file_type + \"/pos/\"\n",
    "    for f in os.listdir(positive_path):\n",
    "        file_list = file_list + [positive_path + f] \n",
    "    \n",
    "    negative_path = path + file_type + \"/neg/\"\n",
    "    for f in os.listdir(negative_path):\n",
    "        file_list = file_list + [negative_path + f] \n",
    "        \n",
    "    print('read', file_type, 'files: ', len(file_list) )\n",
    "    \n",
    "    all_labels = ( [1]*12500 + [0]*12500 )\n",
    "    \n",
    "    all_texts = []\n",
    "    \n",
    "    for f in file_list:\n",
    "        with open(f, encoding='utf8') as file_input:\n",
    "            all_texts = all_texts + [ remove_tags(\" \".join(file_input.readlines() ) ) ] #remove html tags\n",
    "    \n",
    "    return all_labels, all_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files:  25000\n"
     ]
    }
   ],
   "source": [
    "y_train, x_train_text = read_files(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test files:  25000\n"
     ]
    }
   ],
   "source": [
    "y_test, x_test_text = read_files(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer( num_words=2000 )\n",
    "token.fit_on_texts(x_train_text)\n",
    "\n",
    "x_train_seq = token.texts_to_sequences(x_train_text)\n",
    "x_test_seq = token.texts_to_sequences(x_test_text)\n",
    "\n",
    "x_train_final = sequence.pad_sequences( x_train_seq, maxlen=100 )\n",
    "x_test_final = sequence.pad_sequences( x_test_seq, maxlen=100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Embedding layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( Embedding(output_dim=32, input_dim=2000, input_length=100) )\n",
    "model.add( Dropout(0.2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( Flatten() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( Dense(units=256, activation='relu') )\n",
    "model.add( Dropout(0.35) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( Dense(units=1, activation='sigmoid') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 32)           64000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 883,713\n",
      "Trainable params: 883,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 7s - loss: 0.4845 - acc: 0.7535 - val_loss: 0.3823 - val_acc: 0.8388\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.2698 - acc: 0.8902 - val_loss: 0.5258 - val_acc: 0.7744\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.1595 - acc: 0.9409 - val_loss: 0.6485 - val_acc: 0.7620\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0833 - acc: 0.9712 - val_loss: 0.8093 - val_acc: 0.7586\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0491 - acc: 0.9833 - val_loss: 1.1475 - val_acc: 0.7174\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0367 - acc: 0.9867 - val_loss: 1.0633 - val_acc: 0.7560\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0300 - acc: 0.9887 - val_loss: 1.2066 - val_acc: 0.7432\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0240 - acc: 0.9910 - val_loss: 1.1821 - val_acc: 0.7654\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0247 - acc: 0.9910 - val_loss: 1.2533 - val_acc: 0.7576\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0271 - acc: 0.9902 - val_loss: 1.4873 - val_acc: 0.7306\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit( x_train_final, y_train, batch_size=100, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 42us/step\n",
      "0.8118\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate( x_test_final, y_test, verbose=1 )\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(x_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape\n",
    "predict_classes = predict.reshape(-1)\n",
    "predict_classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentDict = {1:'positive', 0:'negative'}\n",
    "def display_test_Sentiment(i):\n",
    "    print(x_test_text[i])\n",
    "    print('[label]')\n",
    "    print('ground truth:', SentimentDict[y_test[i]] ) \n",
    "    print('predict result:', SentimentDict[ predict_classes[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\n",
      "[label]\n",
      "ground truth: positive\n",
      "predict result: positive\n"
     ]
    }
   ],
   "source": [
    "display_test_Sentiment(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\n",
      "[label]\n",
      "ground truth: negative\n",
      "predict result: negative\n"
     ]
    }
   ],
   "source": [
    "display_test_Sentiment(12500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of why the majority of action films are the same. Generic and boring, there's really nothing worth watching here. A complete waste of the then barely-tapped talents of Ice-T and Ice Cube, who've each proven many times over that they are capable of acting, and acting well. Don't bother with this one, go see New Jack City, Ricochet or watch New York Undercover for Ice-T, or Boyz n the Hood, Higher Learning or Friday for Ice Cube and see the real deal. Ice-T's horribly cliched dialogue alone makes this film grate at the teeth, and I'm still wondering what the heck Bill Paxton was doing in this film? And why the heck does he always play the exact same character? From Aliens onward, every film I've seen with Bill Paxton has him playing the exact same irritating character, and at least in Aliens his character died, which made it somewhat gratifying...Overall, this is second-rate action trash. There are countless better films to see, and if you really want to see this one, watch Judgement Night, which is practically a carbon copy but has better acting and a better script. The only thing that made this at all worth watching was a decent hand on the camera - the cinematography was almost refreshing, which comes close to making up for the horrible film itself - but not quite. 4/10.\n",
      "[label]\n",
      "ground truth: negative\n",
      "predict result: negative\n"
     ]
    }
   ],
   "source": [
    "display_test_Sentiment(12501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": 