
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "filePath = \"data/aclImdb_v1.tar.gz\"\n",
    "\n",
    "# note: need to create the directory \"data\" by yourself\n",
    "if not os.path.isfile(filePath):\n",
    "    result = urllib.request.urlretrieve(url, filePath)\n",
    "    print('downloaded: ', result)\n",
    "\n",
    "# unzip the tar file\n",
    "if not os.path.exists(\"data/aclImdb\"):\n",
    "    tempTarFile = tarfile.open(\"data/aclImdb_v1.tar.gz\", 'r:gz')\n",
    "    result = tempTarFile.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regular expression (to remove the HTML tag)\n",
    "import re\n",
    "\n",
    "def remove_tags(text):\n",
    "    regular_expression_tag = re.compile(r'<[^>]+>')\n",
    "    return regular_expression_tag.sub('',text) # replace as ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# read files (positive or negative)\n",
    "def read_files(file_type):\n",
    "    path = \"data/aclImdb/\"\n",
    "    file_list=[]\n",
    "    \n",
    "    positive_path = path + file_type + \"/pos/\"\n",
    "    for f in os.listdir(positive_path):\n",
    "        file_list = file_list + [positive_path + f] \n",
    "    \n",
    "    negative_path = path + file_type + \"/neg/\"\n",
    "    for f in os.listdir(negative_path):\n",
    "        file_list = file_list + [negative_path + f] \n",
    "        \n",
    "    print('read', file_type, 'files: ', len(file_list) )\n",
    "    \n",
    "    all_labels = ( [1]*12500 + [0]*12500 )\n",
    "    \n",
    "    all_texts = []\n",
    "    \n",
    "    for f in file_list:\n",
    "        with open(f, encoding='utf8') as file_input:\n",
    "            all_texts = all_texts + [ remove_tags(\" \".join(file_input.readlines() ) ) ] #remove html tags\n",
    "    \n",
    "    return all_labels, all_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files:  25000\n"
     ]
    }
   ],
   "source": [
    "y_train, x_train_text = read_files(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test files:  25000\n"
     ]
    }
   ],
   "source": [
    "y_test, x_test_text = read_files(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer( num_words=2000 )\n",
    "token.fit_on_texts(x_train_text)\n",
    "\n",
    "x_train_seq = token.texts_to_sequences(x_train_text)\n",
    "x_test_seq = token.texts_to_sequences(x_test_text)\n",
    "\n",
    "x_train_final = sequence.pad_sequences( x_train_seq, maxlen=100 )\n",
    "x_test_final = sequence.pad_sequences( x_test_seq, maxlen=100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Embedding layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import RNN\n",
    "from keras.layers.recurrent import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( Embedding(output_dim=32, input_dim=2000, input_length=100) )\n",
    "model.add( Dropout(0.35) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add RNN\n",
    "model.add( SimpleRNN(units=16) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( Dense(units=256, activation='relu') )\n",
    "model.add( Dropout(0.5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add( Dense(units=1, activation='sigmoid') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 32)           64000     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_7 (SimpleRNN)     (None, 16)                784       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 69,393\n",
      "Trainable params: 69,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 25s - loss: 0.5108 - acc: 0.7408 - val_loss: 0.4331 - val_acc: 0.8026\n",
      "Epoch 2/10\n",
      " - 23s - loss: 0.3594 - acc: 0.8475 - val_loss: 0.5645 - val_acc: 0.7530\n",
      "Epoch 3/10\n",
      " - 23s - loss: 0.3272 - acc: 0.8659 - val_loss: 0.4415 - val_acc: 0.8172\n",
      "Epoch 4/10\n",
      " - 23s - loss: 0.3150 - acc: 0.8680 - val_loss: 0.4863 - val_acc: 0.7770\n",
      "Epoch 5/10\n",
      " - 24s - loss: 0.2929 - acc: 0.8819 - val_loss: 0.3994 - val_acc: 0.8326\n",
      "Epoch 6/10\n",
      " - 24s - loss: 0.2806 - acc: 0.8863 - val_loss: 0.7780 - val_acc: 0.6838\n",
      "Epoch 7/10\n",
      " - 22s - loss: 0.2669 - acc: 0.8911 - val_loss: 0.4477 - val_acc: 0.8142\n",
      "Epoch 8/10\n",
      " - 22s - loss: 0.2400 - acc: 0.9038 - val_loss: 0.3783 - val_acc: 0.8538\n",
      "Epoch 9/10\n",
      " - 23s - loss: 0.2200 - acc: 0.9102 - val_loss: 0.6549 - val_acc: 0.7552\n",
      "Epoch 10/10\n",
      " - 22s - loss: 0.2060 - acc: 0.9182 - val_loss: 0.7878 - val_acc: 0.7314\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit( x_train_final, y_train, batch_size=100, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 37s 1ms/step\n",
      "0.81532\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate( x_test_final, y_test, verbose=1 )\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(x_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape\n",
    "predict_classes = predict.reshape(-1)\n",
    "predict_classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentDict = {1:'positive', 0:'negative'}\n",
    "def display_test_Sentiment(i):\n",
    "    print(x_test_text[i])\n",
    "    print('[label]')\n",
    "    print('ground truth:', SentimentDict[y_test[i]] ) \n",
    "    print('predict result:', SentimentDict[ predict_classes[i] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\n",
      "[label]\n",
      "ground truth: positive\n",
      "predict result: positive\n"